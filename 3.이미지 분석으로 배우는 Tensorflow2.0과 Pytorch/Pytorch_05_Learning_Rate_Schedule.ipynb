{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch - 05. Learning Rate Schedule.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKCs7ds9lrUT"
      },
      "source": [
        "import os\n",
        "from glob import glob\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvQVTLhFmIgi"
      },
      "source": [
        "seed = 1\n",
        "\n",
        "lr = 0.001\n",
        "momentum = 0.5\n",
        "\n",
        "batch_size = 64\n",
        "test_batch_size = 64\n",
        "\n",
        "epochs = 50 # 강의에서는 1000으로 진행하는데, 실습을 위해 에포크 낮춤.\n",
        "no_cuda = False\n",
        "log_interval = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bNzJlkgmQem"
      },
      "source": [
        "# **Modle**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSlUXATHmPpn"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e76t0kzMmcAz"
      },
      "source": [
        "# **Preprocess**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6p_XRYMsR6U"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2c9bv0Cmf-7"
      },
      "source": [
        "train_paths = glob('/content/drive/MyDrive/dataset/mnist_png/training/*/*.png')[:1000]\n",
        "test_paths = glob('/content/drive/MyDrive/dataset/mnist_png/testing/*/*.png')[:1000]\n",
        "len(train_paths), len(test_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAh0C_eampqO"
      },
      "source": [
        "참고: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrCyvS5CmonH"
      },
      "source": [
        "class Dataset(Dataset):\n",
        "    def __init__(self, data_paths, transform=None):\n",
        "\n",
        "        self.data_paths = data_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.data_paths[idx]\n",
        "        image = Image.open(path).convert(\"L\")\n",
        "        label = int(path.split('/')[-2]) # 맥의 경우 경로가 '/'로 구분\n",
        "        #label = int(path.split('\\\\')[-2]) # 윈도우의 경우 경로가 '\\'로 구분되므로 '\\\\'로 표기\n",
        "        \n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cy6mD9U5j9k"
      },
      "source": [
        "torch.manual_seed(seed)\n",
        "\n",
        "use_cuda = not no_cuda and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    Dataset(train_paths, \n",
        "            transforms.Compose([\n",
        "                transforms.RandomHorizontalFlip(), \n",
        "                transforms.ToTensor(), \n",
        "                transforms.Normalize(\n",
        "                    mean=[0.406], \n",
        "                    std=[0.225])])\n",
        "           ),\n",
        "    batch_size=batch_size, \n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    Dataset(test_paths,\n",
        "           transforms.Compose([\n",
        "               transforms.ToTensor(), \n",
        "               transforms.Normalize(\n",
        "                   mean=[0.406], \n",
        "                   std=[0.225])])\n",
        "           ),\n",
        "    batch_size=batch_size, \n",
        "    shuffle=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgB5qW351kVY"
      },
      "source": [
        "for i, data in enumerate(train_loader):\n",
        "  if i == 0:\n",
        "    print(data[0].shape, data[1].shape)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzCEbv9in8pt"
      },
      "source": [
        "# **Optimization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt8q877wnb0q"
      },
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3pqUG9G11Pv"
      },
      "source": [
        "# Learning Rate Scheduler\n",
        "Learning Rate를 중간에 조정할수 있게함\n",
        "만약 loss값이 더 이상 안올라가거나 내려가면 Learning Rate를 더 줄어서 loss값을 더 떨어 트리게 할수 있음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7SwnMXr14cV"
      },
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaRm8Fti2EAp"
      },
      "source": [
        "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, verbose = True)\n",
        "# factor=0.1: 얼마만큼 줄인것인가 0.01 → 0.001\n",
        "#verbose = True : 줄일때 log화면 보여 주겠다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDVlM2kIpGIv"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egT8kUZjoaXq"
      },
      "source": [
        "import torchvision\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mAYgd4WqdEC"
      },
      "source": [
        "writer = SummaryWriter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OHukhM4qdNW"
      },
      "source": [
        "for epoch in range(1, epochs + 1):\n",
        "  # Train Mode\n",
        "  model.train()\n",
        "\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = F.nll_loss(output, target) #https://pytorch.org/docs/stab/nn.html#nll-loss\n",
        "\n",
        "    if batch_idx % log_interval == 0:\n",
        "      print('Train Epoch: {}[{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "          epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "          100. * batch_idx / len(train_loader), loss.item()))\n",
        "      \n",
        "      # Test mode\n",
        "      model.eval()\n",
        "      test_loss = 0\n",
        "      correct = 0\n",
        "      with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "      test_loss /= len(test_loader.dataset)\n",
        "    \n",
        "      accuracy = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "      # Learning Rate Scheduler\n",
        "      scheduler.step(accuracy, epoch)\n",
        "    \n",
        "      print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "          test_loss, correct, len(test_loader.dataset),\n",
        "          accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}